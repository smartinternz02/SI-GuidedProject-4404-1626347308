{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09d82e8",
   "metadata": {},
   "source": [
    "# Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b17adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter as c\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "known-kitchen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ibm_watson_machine_learning in c:\\users\\deepti\\anaconda3\\lib\\site-packages (1.0.116)\n",
      "Requirement already satisfied: tabulate in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (0.8.9)\n",
      "Requirement already satisfied: packaging in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (20.9)\n",
      "Requirement already satisfied: lomond in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (0.3.3)\n",
      "Requirement already satisfied: requests in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (2.25.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (2020.12.5)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (1.26.4)\n",
      "Requirement already satisfied: ibm-cos-sdk==2.7.* in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (2.7.0)\n",
      "Requirement already satisfied: pandas<1.3.0,>=0.24.2 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm_watson_machine_learning) (1.2.4)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.7.0 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm-cos-sdk==2.7.*->ibm_watson_machine_learning) (2.7.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm-cos-sdk==2.7.*->ibm_watson_machine_learning) (0.10.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.7.0 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm-cos-sdk==2.7.*->ibm_watson_machine_learning) (2.7.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk==2.7.*->ibm_watson_machine_learning) (2.8.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk==2.7.*->ibm_watson_machine_learning) (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from pandas<1.3.0,>=0.24.2->ibm_watson_machine_learning) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from pandas<1.3.0,>=0.24.2->ibm_watson_machine_learning) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->ibm-cos-sdk-core==2.7.0->ibm-cos-sdk==2.7.*->ibm_watson_machine_learning) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from requests->ibm_watson_machine_learning) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from requests->ibm_watson_machine_learning) (2.10)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\deepti\\anaconda3\\lib\\site-packages (from packaging->ibm_watson_machine_learning) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install ibm_watson_machine_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c3af1e3",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c065f422",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'credit_train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-589492ffb5eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'credit_train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credit_train.csv'"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('credit_train.csv')\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4f110d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_7e6ae28e13b9413f84d4dfd46572ec7d = 'https://s3.eu.cloud-object-storage.appdomain.cloud'\n",
    "else:\n",
    "    endpoint_7e6ae28e13b9413f84d4dfd46572ec7d = 'https://s3.private.eu.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "client_7e6ae28e13b9413f84d4dfd46572ec7d = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='bxlj9AG3rsG1Qz7n5BmbUOr_rdpRindmfNjGWlhvZ5pu',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_7e6ae28e13b9413f84d4dfd46572ec7d)\n",
    "\n",
    "body = client_7e6ae28e13b9413f84d4dfd46572ec7d.get_object(Bucket='loanstatusprediction-donotdelete-pr-r6nersecsn4kus',Key='credit_train.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "dataset = pd.read_csv(body)\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5ab6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the number of rows and columns\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists out the names of the columns \n",
    "dataset.columns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will display the first five rows of the dataset\n",
    "dataset.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72fcfc",
   "metadata": {},
   "source": [
    "# Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists the  null values in every column of the dataset\n",
    "dataset.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe6ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the  sum of null values in every column of the dataset\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d6f4b",
   "metadata": {},
   "source": [
    "# Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed4589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists the columns with categorical data\n",
    "object_train_df=dataset.select_dtypes(include=['object'])    \n",
    "object_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721604f7",
   "metadata": {},
   "source": [
    "# Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8599a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists the columns with numerical data\n",
    "num_train_df=dataset.select_dtypes(include=['int','float'])     \n",
    "num_train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ac566",
   "metadata": {},
   "source": [
    "# Dropping Loan Status Null Values and Labeling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(subset=['Loan Status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b097be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le =LabelEncoder()\n",
    "dataset['Loan Status'] = le.fit_transform(dataset['Loan Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432bd0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d451409c",
   "metadata": {},
   "source": [
    "# Term column Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34c905",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset['Term'].replace(('Short Term','Long Term'),(0,1),inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3052b2b4",
   "metadata": {},
   "source": [
    "# Scaling Credit Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9292f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying lamda function\n",
    "dataset['Credit Score'] = dataset['Credit Score'].apply(lambda val: (val /10) if val>850 else val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35568a42",
   "metadata": {},
   "source": [
    "# Handling Null values of Credit Score Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_nothing = lambda: None\n",
    "cscoredf = dataset[dataset['Term']==0]\n",
    "stermAVG = cscoredf['Credit Score'].mean()\n",
    "lscoredf = dataset[dataset['Term']==1]\n",
    "ltermAVG = lscoredf['Credit Score'].mean()\n",
    "dataset.loc[(dataset.Term==0) & (dataset['Credit Score'].isnull()),'Credit Score'] = stermAVG\n",
    "dataset.loc[(dataset.Term==1) & (dataset['Credit Score'].isnull()),'Credit Score'] = ltermAVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Credit Score'] = dataset['Credit Score'].apply(lambda val: \"Poor\" if np.isreal(val) and val < 580 else val)\n",
    "dataset['Credit Score'] = dataset['Credit Score'].apply(lambda val: \"Average\" if np.isreal(val) and (val >= 580 and val < 670) else val)\n",
    "dataset['Credit Score'] = dataset['Credit Score'].apply(lambda val: \"Good\" if np.isreal(val) and (val >= 670 and val < 740) else val)\n",
    "dataset['Credit Score'] = dataset['Credit Score'].apply(lambda val: \"Very Good\" if np.isreal(val) and (val >= 740 and val < 800) else val)\n",
    "dataset['Credit Score'] = dataset['Credit Score'].apply(lambda val: \"Exceptional\" if np.isreal(val) and (val >= 800 and val <= 850) else val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2419782e",
   "metadata": {},
   "source": [
    "# Analying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ad272",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The graph lists out the counts in an ascending way\n",
    "dataset['Credit Score'].value_counts().sort_values(ascending = True).plot(kind='bar', title = 'Credit Score category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec9308",
   "metadata": {},
   "source": [
    "# Annual income column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the sum of missing values in the column Annual Income.\n",
    "print(\"There are\",dataset['Annual Income'].isna().sum(), \"Missing Annual Income Values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8427e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#by using fillna function we are filling the null values with the mean method inplace where it is true.\n",
    "dataset['Annual Income'].fillna(dataset['Annual Income'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b98a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the data shape\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51405655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By using the counter function we are to get the count of Good, Very Good and Average.\n",
    "from collections import Counter as c\n",
    "print(c(dataset['Credit Score']))  #returns the class count values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe08e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##applying label encoder\n",
    "dataset['Credit Score'] = le.fit_transform(dataset['Credit Score'])\n",
    "c(dataset['Credit Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce55a95",
   "metadata": {},
   "source": [
    "# Home Ownership Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ab6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Home Ownership Column   we are sorting the elements with values in ascending order. \n",
    "dataset['Home Ownership'].value_counts().sort_values(ascending = True).plot(kind='bar', title=\"Number of Loan based on Home ownership\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Home Ownership']))\n",
    "dataset['Home Ownership'] =  le.fit_transform(dataset['Home Ownership'])\n",
    "print(c(dataset['Home Ownership']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0808fe",
   "metadata": {},
   "source": [
    "# Years in current job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0486d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Years in current job']=dataset['Years in current job'].str.extract(r\"(\\d+)\")\n",
    "dataset['Years in current job'] = dataset['Years in current job'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "expmean = dataset['Years in current job'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ca847",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Years in current job'].fillna(expmean, inplace=True)\n",
    "dataset['Years in current job'].fillna(expmean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41caa288",
   "metadata": {},
   "source": [
    "# Dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4542f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Loan ID','Customer ID','Purpose'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280443d1",
   "metadata": {},
   "source": [
    "# Credit Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e29bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing \n",
    "dataset['Credit Problems'] = dataset['Number of Credit Problems'].apply(lambda x: \"No Credit Problem\" if x==0 else (\"Some Credit promblem\" if x>0 and x<5 else \"Major Credit Problems\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6652518",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Credit Problems']))\n",
    "dataset['Credit Problems'] = le.fit_transform(dataset['Credit Problems'])\n",
    "print(c(dataset['Credit Problems']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159115c4",
   "metadata": {},
   "source": [
    "# Credit Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825009c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Credit Age'] = dataset['Years of Credit History'].apply(lambda x: \"Short Credit Age\" if x<5 \n",
    "                                else (\"Good Credit Age\" if x>5 and x<17 else \"Exceptional Credit Age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Credit Age']))\n",
    "dataset['Credit Age'] = le.fit_transform(dataset['Credit Age'])\n",
    "print(c(dataset['Credit Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6884874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['Months since last delinquent','Number of Open Accounts',\n",
    "                  'Maximum Open Credit','Current Credit Balance','Monthly Debt'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932da2a6",
   "metadata": {},
   "source": [
    "# Tax Liens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Tax Liens'] = dataset['Tax Liens'].apply(lambda x: \"No Tax Lien\" if x==0 else (\"Some Tax Liens\" if x>0 and x<3 else \"Many Tax Liens\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Tax Liens']))\n",
    "dataset['Tax Liens'] = le.fit_transform(dataset['Tax Liens'])\n",
    "print(c(dataset['Tax Liens']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfafbe2",
   "metadata": {},
   "source": [
    "# Bankruptcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac07e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Bankruptcies'] = dataset['Bankruptcies'].apply(lambda x: \"No bankruptcies\" if x==0  else (\"Some Bankruptcies\" if x>0 and x<3 else \"Many Bankruptcies\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cbf24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Bankruptcies']))\n",
    "dataset['Bankruptcies'] = le.fit_transform(dataset['Bankruptcies'])\n",
    "print(c(dataset['Bankruptcies']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95529d5",
   "metadata": {},
   "source": [
    "# Annual Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b33af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "meanxoutlier = dataset[dataset['Annual Income'] < 99999999.00 ]['Annual Income'].mean()\n",
    "stddevxoutlier = dataset[dataset['Annual Income'] < 99999999.00 ]['Annual Income'].std()\n",
    "poorline = meanxoutlier -  stddevxoutlier\n",
    "richline = meanxoutlier + stddevxoutlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede2980",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Annual Income'] = dataset['Annual Income'].apply(lambda x: \"Low Income\" if x<=poorline  else (\"Average Income\" if x>poorline and x<richline else \"High Income\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bceae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Annual Income']))\n",
    "dataset['Annual Income'] = le.fit_transform(dataset['Annual Income'])\n",
    "print(c(dataset['Annual Income']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00c244",
   "metadata": {},
   "source": [
    "# Current Loan Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915475e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmeanxoutlier = dataset[dataset['Current Loan Amount'] < 99999999.00 ]['Current Loan Amount'].mean()\n",
    "lstddevxoutlier = dataset[dataset['Current Loan Amount'] < 99999999.00 ]['Current Loan Amount'].std()\n",
    "lowrange = lmeanxoutlier - lstddevxoutlier\n",
    "highrange = lmeanxoutlier + lstddevxoutlier\n",
    "print(lowrange, highrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6a6b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Current Loan Amount'] = dataset['Current Loan Amount'].apply(lambda x: \"Small Loan\" if x<=lowrange else (\"Medium Loan\" if x>lowrange and x<highrange else \"Big Loan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b04c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c(dataset['Current Loan Amount']))\n",
    "dataset['Current Loan Amount'] = le.fit_transform(dataset['Current Loan Amount'])\n",
    "print(c(dataset['Current Loan Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c21ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c022059",
   "metadata": {},
   "source": [
    "# Seperating Dependent and Independent Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2727fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset['Loan Status']\n",
    "X = dataset.drop(['Loan Status'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce3cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f21690b",
   "metadata": {},
   "source": [
    "# Performing Train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67df12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140830a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By using DecisionTree we are fitting the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-custom",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aed293",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt =dt.predict(X_test)  #prediction\n",
    "c(y_pred_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred_dt,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials = {\n",
    "                 \"url\": \"https://eu-gb.ml.cloud.ibm.com\",\n",
    "                 \"apikey\":\"bxlj9AG3rsG1Qz7n5BmbUOr_rdpRindmfNjGWlhvZ5pu\"\n",
    "                  }\n",
    "client =  APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    #print(space)\n",
    "    return(next(item for item in space['resources']if item['entity'][\"name\"] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_uid= guid_from_space_name(client, 'newspace')\n",
    "print(\"Space UID=\" +space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-aggregate",
   "metadata": {},
   "outputs": [],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"default_py3.7\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offshore-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_details = client.repository.store_model(model=dt,meta_props={\n",
    " client.repository.ModelMetaNames.NAME:\"Loan_Prediction\",\n",
    " client.repository.ModelMetaNames.TYPE:\"scikit-learn_0.23\", \n",
    " client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid }\n",
    "                                        )\n",
    "model_id = client.repository.get_model_uid(model_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-parade",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be94a3c8",
   "metadata": {},
   "source": [
    "# Creating a pickle file dumping the model in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc793b1",
   "metadata": {},
   "outputs": [],
   "source": [
    " #importing the pickle file\n",
    "import pickle \n",
    "#Dumping the model into the pickle file\n",
    "pickle.dump(dt,open('loan.pkl','wb'))   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
